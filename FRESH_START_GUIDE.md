# ğŸš€ **HÆ°á»›ng Dáº«n Báº¯t Äáº§u Láº¡i Tá»« Con Sá»‘ 0 vá»›i 4 Video Má»›i**

## âš¡ **PHÆ¯Æ NG PHÃP Äá»€ XUáº¤T - ÄÆ¡n Giáº£n Nháº¥t (Chá»‰ 3 BÆ°á»›c)**

### **ï¿½ ÄÃ¢y LÃ  CÃ¡ch Báº¡n NÃªn LÃ m**

```bash
# BÆ°á»›c 1: Copy 4 video má»›i vÃ o thÆ° má»¥c videos/ (thay tháº¿ video cÅ©)
# Drag & drop hoáº·c copy video má»›i vÃ o videos/

# BÆ°á»›c 2: XÃ³a folder frames Ä‘á»ƒ há»‡ thá»‘ng rebuild
# Windows: Delete thÆ° má»¥c frames/ báº±ng File Explorer
# Hoáº·c: Remove-Item -Recurse -Force frames

# BÆ°á»›c 3: Cháº¡y láº¡i setup - Tá»± Ä‘á»™ng rebuild má»i thá»©
python setup.py
```

### **ğŸ“ Chi Tiáº¿t Tá»«ng BÆ°á»›c**

#### **BÆ°á»›c 1: Thay Tháº¿ Video**
```bash
# CÃ¡ch 1: Drag & Drop (Dá»… nháº¥t)
# - Má»Ÿ thÆ° má»¥c videos/
# - XÃ³a 4 video cÅ©
# - Drag & drop 4 video má»›i vÃ o

# CÃ¡ch 2: Command Line
# Windows PowerShell:
Copy-Item "C:\path\to\your\new\videos\*" "videos\"

# Linux/Mac:
cp /path/to/your/new/videos/* videos/
```

#### **BÆ°á»›c 2: XÃ³a Frames CÅ©**
```bash
# Windows - File Explorer:
# Chuá»™t pháº£i folder "frames" â†’ Delete

# Windows - PowerShell:
Remove-Item -Recurse -Force frames

# Linux/Mac:
rm -rf frames/
```

#### **BÆ°á»›c 3: Rebuild Tá»± Äá»™ng**
```bash
# KÃ­ch hoáº¡t virtual environment (náº¿u chÆ°a)
.\.venv\Scripts\Activate.ps1  # Windows
source .venv/bin/activate     # Linux/Mac

# Cháº¡y setup - Tá»± Ä‘á»™ng xá»­ lÃ½ má»i thá»©
python setup.py

# Setup sáº½ tá»± Ä‘á»™ng:
# âœ… PhÃ¡t hiá»‡n video má»›i trong videos/
# âœ… Extract frames tá»« 4 video má»›i
# âœ… Build embeddings vá»›i CLIP model
# âœ… Táº¡o FAISS index cho search
# âœ… Chuáº©n bá»‹ sáºµn sÃ ng cho web interface
```

### **âœ… Káº¿t Quáº£ Sau Khi HoÃ n ThÃ nh**

```
Project/
â”œâ”€â”€ videos/                        # 4 video má»›i cá»§a báº¡n
â”‚   â”œâ”€â”€ your_new_video1.mp4
â”‚   â”œâ”€â”€ your_new_video2.mp4  
â”‚   â”œâ”€â”€ your_new_video3.mp4
â”‚   â””â”€â”€ your_new_video4.mp4
â”œâ”€â”€ frames/                        # Frames má»›i (tá»± Ä‘á»™ng táº¡o)
â”‚   â”œâ”€â”€ your_new_video1/
â”‚   â”‚   â”œâ”€â”€ frame_000001.jpg
â”‚   â”‚   â”œâ”€â”€ frame_000002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ your_new_video2/
â”‚   â”œâ”€â”€ your_new_video3/
â”‚   â””â”€â”€ your_new_video4/
â”œâ”€â”€ index/                         # Index má»›i (tá»± Ä‘á»™ng táº¡o)
â”‚   â”œâ”€â”€ metadata.json             # Metadata cá»§a frames má»›i
â”‚   â””â”€â”€ faiss/                    # FAISS search index
â”œâ”€â”€ embeddings/                    # Embeddings má»›i (tá»± Ä‘á»™ng táº¡o)
â””â”€â”€ models_cache/                  # Models cache (giá»¯ nguyÃªn)
```

### **ğŸš€ Test Há»‡ Thá»‘ng Má»›i**

```bash
# Sau khi setup xong, start web interface
python web_interface.py

# Truy cáº­p: http://localhost:8080
# Test search vá»›i ná»™i dung video má»›i
```

---

## ğŸ“¦ **PHÆ¯Æ NG PHÃP BACKUP (Náº¿u Muá»‘n Giá»¯ Dá»¯ Liá»‡u CÅ©)**

### **ğŸ”’ An ToÃ n HÆ¡n - Backup TrÆ°á»›c Khi XÃ³a**

```bash
# BÆ°á»›c 1: Táº¡o thÆ° má»¥c backup vá»›i timestamp
mkdir backup_$(Get-Date -Format "yyyyMMdd_HHmmss")  # Windows PowerShell
mkdir backup_$(date +%Y%m%d_%H%M%S)                # Linux/Mac

# BÆ°á»›c 2: Backup dá»¯ liá»‡u quan trá»ng
# Windows PowerShell:
Move-Item videos backup_*/videos_old
Move-Item frames backup_*/frames_old  
Move-Item index backup_*/index_old
Move-Item embeddings backup_*/embeddings_old

# Linux/Mac:
mv videos backup_*/videos_old
mv frames backup_*/frames_old
mv index backup_*/index_old  
mv embeddings backup_*/embeddings_old

# BÆ°á»›c 3: Táº¡o thÆ° má»¥c má»›i vÃ  setup
mkdir videos frames index embeddings
# Copy video má»›i vÃ o videos/
python setup.py
```

### **ğŸ—‚ï¸ Hoáº·c Táº¡o Dataset Song Song**

```bash
# Giá»¯ nguyÃªn dataset cÅ©, táº¡o dataset má»›i
mkdir videos_new frames_new index_new embeddings_new

# Copy video má»›i vÃ o videos_new/
# Sáº½ cáº§n script Ä‘áº·c biá»‡t Ä‘á»ƒ xá»­ lÃ½ (hÆ°á»›ng dáº«n bÃªn dÆ°á»›i)
```

---

## ï¿½ **CÃ¢u Há»i ThÆ°á»ng Gáº·p**

### **â“ TÃ´i CÃ³ Cáº§n XÃ³a Folder NÃ o KhÃ´ng?**

**ÄÃ¡p**: **KHÃ”NG báº¯t buá»™c!** Báº¡n cÃ³ 2 lá»±a chá»n:

#### **ğŸ¯ Lá»±a chá»n 1: Cháº¡y Ä‘Ã¨ (Äá» xuáº¥t)**
```bash
# Chá»‰ cáº§n copy video má»›i vÃ o videos/ vÃ  cháº¡y
python setup.py

# Há»‡ thá»‘ng tá»± Ä‘á»™ng ghi Ä‘Ã¨:
# âœ… frames/ â†’ Frames má»›i tá»« video má»›i
# âœ… index/ â†’ Metadata vÃ  index má»›i  
# âœ… embeddings/ â†’ Embeddings má»›i
```

#### **ğŸ”’ Lá»±a chá»n 2: XÃ³a clean (An toÃ n hÆ¡n)**
```bash
# XÃ³a Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng bá»‹ conflict
Remove-Item -Recurse -Force frames  # Windows
rm -rf frames/                      # Linux/Mac

# Rá»“i cháº¡y setup
python setup.py
```

### **â“ Folder Models_cache/ CÃ³ Cáº§n XÃ³a KhÃ´ng?**

**ÄÃ¡p**: **KHÃ”NG!** Giá»¯ nguyÃªn Ä‘á»ƒ trÃ¡nh download láº¡i models:
```bash
# GIá»® NGUYÃŠN - Äá»«ng xÃ³a
models_cache/           # CLIP, BLIP models Ä‘Ã£ download
.venv/                  # Python environment
config/                 # Configuration files
```

### **â“ File frames/search_index_lite.json vÃ  .gitkeep CÃ³ Cáº§n Táº¡o Láº¡i KhÃ´ng?**

**ÄÃ¡p**: **Tá»° Äá»˜NG Táº O Láº I!** KhÃ´ng cáº§n lo láº¯ng:

#### **ğŸ“„ search_index_lite.json**
```python
# File nÃ y chá»©a metadata cá»§a frames cho AI Search Lite
# Sáº¼ ÄÆ¯á»¢C Táº O Tá»° Äá»˜NG khi:
# 1. Cháº¡y ai_search_lite.py
# 2. Process frames má»›i
# 3. Extract features (brightness, contrast, color...)

# Vá»‹ trÃ­: frames/search_index_lite.json
# Táº¡o bá»Ÿi: ai_search_lite.py â†’ _save_index()
```

#### **ğŸ“ .gitkeep** 
```bash
# File nÃ y chá»‰ Ä‘á»ƒ Git tracking folder rá»—ng
# CÃ“ THá»‚ Táº O Láº I Ä‘Æ¡n giáº£n:

# Windows PowerShell:
New-Item -ItemType File -Path "frames/.gitkeep" -Force

# Linux/Mac:
touch frames/.gitkeep

# Hoáº·c Ä‘á»ƒ Git tá»± táº¡o khi commit
```

#### **âš¡ Quy TrÃ¬nh Tá»± Äá»™ng:**
```bash
# Khi xÃ³a folder frames/ vÃ  cháº¡y setup.py:
# 1. setup.py â†’ táº¡o folder frames/ má»›i
# 2. Extract frames â†’ frame_000001.jpg, frame_000002.jpg...
# 3. ai_search_lite.py â†’ tá»± Ä‘á»™ng táº¡o search_index_lite.json
# 4. .gitkeep â†’ táº¡o thá»§ cÃ´ng (khÃ´ng báº¯t buá»™c)
```

### **â“ Folder datasets/ CÃ³ Cáº§n Thay Äá»•i GÃ¬ KhÃ´ng?**

**ÄÃ¡p Ã¡n**: **TÃ™Y CHá»ŒN!** ÄÃ¢y lÃ  system quáº£n lÃ½ multi-dataset:

#### **ğŸ“Š Hiá»‡n Táº¡i: Multi-Dataset System**
```bash
datasets/
â”œâ”€â”€ mixed_collection/        # Collection 1
â”‚   â”œâ”€â”€ videos/             # Videos cá»§a collection nÃ y
â”‚   â”œâ”€â”€ frames/             # Frames riÃªng
â”‚   â”œâ”€â”€ index/              # Index riÃªng  
â”‚   â””â”€â”€ config.json         # Metadata
â”œâ”€â”€ nature_collection/       # Collection 2
â”‚   â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ frames/ 
â”‚   â”œâ”€â”€ index/
â”‚   â””â”€â”€ config.json
â””â”€â”€ people_collection/       # Collection 3
    â””â”€â”€ ...
```

#### **ğŸ¯ 2 Lá»±a Chá»n:**

**ğŸ”¹ Lá»±a chá»n 1: Chá»‰ dÃ¹ng Default Dataset (ÄÆ¡n giáº£n)**
```bash
# KHÃ”NG Cáº¦N Ä‘á»™ng vÃ o datasets/
# Chá»‰ cáº§n lÃ m viá»‡c vá»›i:
videos/                     # â† 4 video má»›i á»Ÿ Ä‘Ã¢y
frames/                     # â† XÃ³a vÃ  táº¡o láº¡i
index/                      # â† Tá»± Ä‘á»™ng ghi Ä‘Ã¨
embeddings/                 # â† Tá»± Ä‘á»™ng ghi Ä‘Ã¨

# datasets/ â†’ GIá»® NGUYÃŠN (khÃ´ng áº£nh hÆ°á»Ÿng)
```

**ğŸ”¹ Lá»±a chá»n 2: Reset Cáº£ Multi-Dataset System**
```bash
# Náº¿u muá»‘n clean hoÃ n toÃ n:
Remove-Item -Recurse -Force datasets    # Windows
rm -rf datasets/                        # Linux

# Khi cháº¡y web_interface.py â†’ tá»± táº¡o láº¡i datasets/ rá»—ng
```

#### **âš¡ Khuyáº¿n Nghá»‹:**
```bash
# ğŸ¯ GIá»® NGUYÃŠN datasets/ 
# VÃ¬:
# âœ… KhÃ´ng áº£nh hÆ°á»Ÿng default dataset
# âœ… CÃ³ thá»ƒ dÃ¹ng multi-dataset sau nÃ y
# âœ… Web interface váº«n hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng
# âœ… KhÃ´ng cáº§n setup thÃªm gÃ¬

# Chá»‰ cáº§n focus vÃ o 3 bÆ°á»›c chÃ­nh:
# 1. videos/ â† 4 video má»›i
# 2. frames/ â† XÃ³a
# 3. python setup.py â† Cháº¡y
```

### **â“ CÃ³ Bá»‹ Conflict Giá»¯a Dá»¯ Liá»‡u CÅ© vÃ  Má»›i KhÃ´ng?**

**ÄÃ¡p**: **KHÃ”NG!** Setup.py thÃ´ng minh:
```python
# setup.py tá»± Ä‘á»™ng:
# 1. Detect video files trong videos/
# 2. Ghi Ä‘Ã¨ frames cÅ© vá»›i frames má»›i
# 3. Rebuild embeddings hoÃ n toÃ n má»›i
# 4. Overwrite metadata vÃ  index
# â†’ KhÃ´ng cÃ³ conflict!
```

### **â“ Bao LÃ¢u Setup Má»›i HoÃ n ThÃ nh?**

**ÄÃ¡p**: TÃ¹y thuá»™c vÃ o video:
```bash
# Æ¯á»›c tÃ­nh thá»i gian:
- Extract frames: ~1-2 phÃºt/video
- Build embeddings: ~3-5 phÃºt (GPU RTX 3060)
- Create index: ~30 giÃ¢y

# Tá»•ng: ~15-20 phÃºt cho 4 video
```

---

## ğŸš€ **Script Tá»± Äá»™ng HoÃ n Chá»‰nh**

### **ğŸ“œ Script All-in-One**

```bash
# Táº¡o file: quick_reset.ps1 (Windows)
# Copy 4 video má»›i vÃ o videos/
Write-Host "ğŸ¬ Copying new videos..."
# (Manual step: user copies videos)

# XÃ³a frames cÅ© Ä‘á»ƒ rebuild clean
Write-Host "ğŸ—‘ï¸ Removing old frames..."
if (Test-Path "frames") {
    Remove-Item -Recurse -Force frames
}

# Cháº¡y setup tá»± Ä‘á»™ng
Write-Host "ğŸš€ Running setup..."
python setup.py

# Start web interface
Write-Host "ğŸŒ Starting web interface..."
python web_interface.py
```

```bash
# Táº¡o file: quick_reset.sh (Linux/Mac)
#!/bin/bash
echo "ğŸ¬ Ready for new videos in videos/ folder"
echo "ğŸ—‘ï¸ Removing old frames..."
rm -rf frames/

echo "ğŸš€ Running setup..."
python setup.py

echo "ğŸŒ Starting web interface..."
python web_interface.py
``` 
# - Build láº¡i embeddings
# - Cáº­p nháº­t FAISS index

echo "âœ… KhÃ´ng cáº§n xÃ³a gÃ¬ - há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng ghi Ä‘Ã¨!"
```

### **ï¿½ Cáº¥u TrÃºc ThÆ° Má»¥c - Ghi ÄÃ¨**

```
Project/
â”œâ”€â”€ videos/                        # Thay 4 video cÅ© báº±ng 4 video má»›i
â”‚   â”œâ”€â”€ new_video1.mp4             # â† Thay tháº¿ video cÅ©
â”‚   â”œâ”€â”€ new_video2.mp4             # â† Thay tháº¿ video cÅ©  
â”‚   â”œâ”€â”€ new_video3.mp4             # â† Video má»›i
â”‚   â””â”€â”€ new_video4.mp4             # â† Video má»›i
â”œâ”€â”€ frames/                        # Sáº½ Ä‘Æ°á»£c ghi Ä‘Ã¨ tá»± Ä‘á»™ng
â”œâ”€â”€ index/                         # Metadata má»›i sáº½ ghi Ä‘Ã¨
â””â”€â”€ embeddings/                    # Embeddings má»›i sáº½ ghi Ä‘Ã¨
```

### **ğŸ—‘ï¸ TÃ™Y CHá»ŒN: XÃ³a Dá»¯ Liá»‡u CÅ© (Náº¿u Muá»‘n Clean Start)**

```bash
# Option 1: Backup dá»¯ liá»‡u cÅ© (An toÃ n)
mkdir backup_$(date +%Y%m%d_%H%M%S)
cp -r frames/ backup_$(date +%Y%m%d_%H%M%S)/frames_old
cp -r index/ backup_$(date +%Y%m%d_%H%M%S)/index_old  
cp -r embeddings/ backup_$(date +%Y%m%d_%H%M%S)/embeddings_old

# Sau Ä‘Ã³ xÃ³a Ä‘á»ƒ clean start
rm -rf frames/* index/* embeddings/*

# Option 2: XÃ³a hoÃ n toÃ n (Cáº¢NH BÃO: Máº¥t dá»¯ liá»‡u cÅ©)
# CHá»ˆ dÃ¹ng khi cháº¯c cháº¯n khÃ´ng cáº§n dá»¯ liá»‡u cÅ©
rm -rf frames/ index/ embeddings/
mkdir frames index embeddings

# Option 3: XÃ³a cache models (náº¿u muá»‘n download láº¡i models)
rm -rf models_cache/
```

### **ğŸ”„ Hoáº·c Táº¡o Dataset Song Song**

```bash
# Táº¡o dataset má»›i song song vá»›i dataset cÅ©
mkdir videos_new frames_new index_new embeddings_new

# Äáº·t video má»›i vÃ o videos_new/
# Sau nÃ y cÃ³ thá»ƒ switch giá»¯a 2 datasets
```

---

## âš™ï¸ **BÆ°á»›c 3: Cáº¥u HÃ¬nh Há»‡ Thá»‘ng**

### **ğŸ”§ Cáº­p Nháº­t Configuration**

```python
# Táº¡o file config_new.py
import os
from pathlib import Path

class NewDatasetConfig:
    """Configuration cho dataset má»›i"""
    
    # Paths for new dataset
    PROJECT_ROOT = Path(__file__).parent
    VIDEOS_PATH = PROJECT_ROOT / "videos_new"
    FRAMES_PATH = PROJECT_ROOT / "frames_new"
    INDEX_PATH = PROJECT_ROOT / "index_new"
    EMBEDDINGS_PATH = PROJECT_ROOT / "embeddings_new"
    
    # Video processing settings
    FPS_EXTRACTION = 1  # Extract 1 frame per second
    MAX_FRAMES_PER_VIDEO = 1000  # Giá»›i háº¡n frames má»—i video
    
    # Model settings
    DEFAULT_MODEL = "clip_vit_base"
    BATCH_SIZE = 32
    GPU_MEMORY_FRACTION = 0.8
    
    # Frame processing
    FRAME_SIZE = (224, 224)
    IMAGE_QUALITY = 95
```

---

## ğŸ¬ **BÆ°á»›c 4: Extract Frames tá»« 4 Video Má»›i (Ghi ÄÃ¨)**

### **ğŸ“ Script Extract Frames - PhiÃªn Báº£n Ghi ÄÃ¨**

```python
# Táº¡o file: extract_frames_overwrite.py
import cv2
import os
from pathlib import Path
import json
from datetime import datetime

def extract_frames_overwrite_old_data():
    """
    Extract frames tá»« 4 video má»›i - GHI ÄÃˆ dá»¯ liá»‡u cÅ©
    KHÃ”NG cáº§n xÃ³a gÃ¬ trÆ°á»›c Ä‘Ã³
    """
    
    videos_path = Path("videos")          # Sá»­ dá»¥ng thÆ° má»¥c videos hiá»‡n táº¡i
    frames_path = Path("frames")          # Ghi Ä‘Ã¨ vÃ o thÆ° má»¥c frames cÅ©
    index_path = Path("index")            # Ghi Ä‘Ã¨ metadata cÅ©
    
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    frames_path.mkdir(exist_ok=True)
    index_path.mkdir(exist_ok=True)
    
    print("ğŸš€ Starting frame extraction - OVERWRITE MODE")
    print("ğŸ“ Videos from:", videos_path)
    print("ğŸ“ Frames to:", frames_path)
    print("âš ï¸  Will overwrite existing data!")
    
    # XÃ³a ná»™i dung cÅ© trong frames (giá»¯ láº¡i thÆ° má»¥c)
    import shutil
    for item in frames_path.iterdir():
        if item.is_dir():
            shutil.rmtree(item)
        else:
            item.unlink()
    
    metadata = []
    total_frames = 0
    
    # Láº¥y táº¥t cáº£ video files
    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv']
    video_files = []
    for ext in video_extensions:
        video_files.extend(videos_path.glob(ext))
    
    print(f"ğŸ¬ Found {len(video_files)} video files")
    
    if len(video_files) == 0:
        print("âŒ No video files found in videos/ folder!")
        print("ğŸ“ Please put your 4 new videos in the videos/ folder")
        return False
    
    for video_file in video_files:
        print(f"\nğŸ”„ Processing: {video_file.name}")
        
        # Táº¡o thÆ° má»¥c cho video
        video_name = video_file.stem
        video_frames_dir = frames_path / video_name
        video_frames_dir.mkdir(exist_ok=True)
        
        # Extract frames
        cap = cv2.VideoCapture(str(video_file))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if fps <= 0:
            print(f"   âŒ Invalid FPS for {video_file.name}")
            continue
            
        duration = total_video_frames / fps
        
        print(f"   ğŸ“Š FPS: {fps:.1f}, Total frames: {total_video_frames}, Duration: {duration:.1f}s")
        
        frame_count = 0
        extracted_count = 0
        
        # Extract 1 frame per second
        frame_interval = max(1, int(fps))  # Extract every fps frames (1 per second)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Extract frame every second
            if frame_count % frame_interval == 0:
                frame_filename = f"frame_{extracted_count+1:06d}.jpg"
                frame_path = video_frames_dir / frame_filename
                
                # Save frame
                success = cv2.imwrite(str(frame_path), frame)
                
                if success:
                    # Calculate timestamp
                    timestamp = frame_count / fps
                    
                    # Add to metadata
                    metadata.append({
                        "frame_id": f"{video_name}_{extracted_count+1:06d}",
                        "video_name": video_name,
                        "video_path": str(video_file),
                        "frame_path": str(frame_path),
                        "frame_number": frame_count,
                        "timestamp_seconds": timestamp,
                        "timestamp_formatted": f"{int(timestamp//60):02d}:{int(timestamp%60):02d}",
                        "extraction_date": datetime.now().isoformat()
                    })
                    
                    extracted_count += 1
                    
                    if extracted_count % 100 == 0:
                        print(f"   ğŸ”„ Extracted {extracted_count} frames...")
            
            frame_count += 1
        
        cap.release()
        total_frames += extracted_count
        print(f"   âœ… Extracted {extracted_count} frames from {video_name}")
    
    # Save metadata (GHI ÄÃˆ file cÅ©)
    metadata_path = index_path / "metadata.json"
    
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # Táº¡o file frames_meta.json cho compatibility
    frames_meta_path = Path("frames") / "search_index_lite.json"
    frames_meta = {
        "total_frames": total_frames,
        "videos": len(video_files),
        "last_updated": datetime.now().isoformat(),
        "metadata": metadata
    }
    
    with open(frames_meta_path, 'w', encoding='utf-8') as f:
        json.dump(frames_meta, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ OVERWRITE EXTRACTION COMPLETE!")
    print(f"ğŸ“Š Total videos processed: {len(video_files)}")
    print(f"ğŸ“Š Total frames extracted: {total_frames}")
    print(f"ğŸ“ Frames overwritten in: {frames_path}")
    print(f"ğŸ“„ Metadata overwritten: {metadata_path}")
    print(f"ğŸ”„ Old data has been replaced with new data")
    
    return metadata

if __name__ == "__main__":
    print("ğŸš€ FRAME EXTRACTION - OVERWRITE MODE")
    print("=" * 50)
    
    # Kiá»ƒm tra thÆ° má»¥c videos
    videos_path = Path("videos")
    if not videos_path.exists():
        print("âŒ videos/ folder not found!")
        print("ğŸ“ Creating videos/ folder - please put your 4 videos there")
        videos_path.mkdir()
        exit(1)
    
    # Confirm overwrite
    response = input("âš ï¸  This will OVERWRITE existing frames and metadata. Continue? (y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ Operation cancelled")
        exit(0)
    
    metadata = extract_frames_overwrite_old_data()
    
    if metadata:
        print(f"\nâœ… Ready for next step: build embeddings")
        print(f"â–¶ï¸  Run: python build_embeddings_overwrite.py")
```

### **ğŸš€ Cháº¡y Frame Extraction (Ghi ÄÃ¨)**

```bash
# BÆ°á»›c 1: Äáº·t 4 video má»›i vÃ o thÆ° má»¥c videos/
cp /path/to/your/new_video1.mp4 videos/
cp /path/to/your/new_video2.mp4 videos/
cp /path/to/your/new_video3.mp4 videos/
cp /path/to/your/new_video4.mp4 videos/

# BÆ°á»›c 2: Cháº¡y script extract (sáº½ ghi Ä‘Ã¨ tá»± Ä‘á»™ng)
python extract_frames_overwrite.py

# Kiá»ƒm tra káº¿t quáº£
ls -la frames/
ls -la index/metadata.json
```

---

## ğŸ§  **BÆ°á»›c 5: Build Embeddings cho Dataset Má»›i (Ghi ÄÃ¨)**

### **ğŸ“ Script Build Embeddings - PhiÃªn Báº£n Ghi ÄÃ¨**

```python
# Táº¡o file: build_embeddings_overwrite.py
import json
import numpy as np
from pathlib import Path
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel
import faiss
from tqdm import tqdm

def build_embeddings_overwrite():
    """
    Build embeddings cho dataset má»›i - GHI ÄÃˆ embeddings cÅ©
    Sá»­ dá»¥ng metadata tá»« extract_frames_overwrite.py
    """
    
    # Load metadata tá»« index/metadata.json
    metadata_path = Path("index") / "metadata.json"
    
    if not metadata_path.exists():
        print("âŒ metadata.json not found!")
        print("ğŸ“ Please run extract_frames_overwrite.py first")
        return False
    
    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print(f"ğŸ“Š Loading {len(metadata)} frames metadata")
    
    # Initialize CLIP model
    model_name = "openai/clip-vit-base-patch32"
    print(f"ğŸš€ Loading CLIP model: {model_name}")
    
    processor = CLIPProcessor.from_pretrained(model_name)
    model = CLIPModel.from_pretrained(model_name)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    model.eval()
    
    print(f"ğŸš€ CLIP model loaded on {device}")
    
    # Táº¡o thÆ° má»¥c embeddings (ghi Ä‘Ã¨)
    embeddings_path = Path("embeddings")
    embeddings_path.mkdir(exist_ok=True)
    
    # XÃ³a embeddings cÅ©
    for file in embeddings_path.glob("*.npy"):
        file.unlink()
    for file in embeddings_path.glob("*.pkl"):
        file.unlink()
    
    print("ğŸ—‘ï¸  Cleared old embeddings")
    
    # Build embeddings
    embeddings = []
    valid_metadata = []
    
    batch_size = 32
    
    print("ğŸ”„ Building new embeddings...")
    
    for i in tqdm(range(0, len(metadata), batch_size), desc="Processing batches"):
        batch_metadata = metadata[i:i+batch_size]
        batch_images = []
        batch_valid_metadata = []
        
        # Load batch images
        for item in batch_metadata:
            frame_path = Path(item["frame_path"])
            if frame_path.exists():
                try:
                    image = Image.open(frame_path).convert('RGB')
                    batch_images.append(image)
                    batch_valid_metadata.append(item)
                except Exception as e:
                    print(f"âš ï¸ Error loading {frame_path}: {e}")
        
        if batch_images:
            # Process batch
            inputs = processor(images=batch_images, return_tensors="pt", padding=True)
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            with torch.no_grad():
                image_features = model.get_image_features(**inputs)
                image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
            
            embeddings.extend(image_features.cpu().numpy())
            valid_metadata.extend(batch_valid_metadata)
    
    embeddings = np.array(embeddings)
    
    print(f"âœ… Built embeddings for {len(embeddings)} frames")
    print(f"ğŸ“Š Embedding shape: {embeddings.shape}")
    
    # Save embeddings (GHI ÄÃˆ)
    np.save(embeddings_path / "clip_vit_base_embeddings.npy", embeddings)
    
    # Save valid metadata (GHI ÄÃˆ)
    with open(Path("index") / "valid_metadata.json", 'w', encoding='utf-8') as f:
        json.dump(valid_metadata, f, indent=2, ensure_ascii=False)
    
    # Build FAISS index (GHI ÄÃˆ)
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity
    index.add(embeddings.astype('float32'))
    
    # Save FAISS index (GHI ÄÃˆ)
    faiss_path = Path("index") / "faiss"
    faiss_path.mkdir(exist_ok=True)
    
    # XÃ³a FAISS index cÅ©
    for file in faiss_path.glob("*.index"):
        file.unlink()
    for file in faiss_path.glob("*.faiss"):
        file.unlink()
    
    # Save index má»›i
    faiss.write_index(index, str(faiss_path / "clip_vit_base.index"))
    
    # Táº¡o file embeddings cho compatibility
    embeddings_dict = {
        "clip_vit_base": {
            "embeddings": embeddings.tolist(),
            "metadata": valid_metadata,
            "model_name": model_name,
            "dimension": dimension,
            "total_frames": len(embeddings)
        }
    }
    
    with open(embeddings_path / "clip_vit_base.json", 'w', encoding='utf-8') as f:
        json.dump(embeddings_dict, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Embeddings saved to: {embeddings_path}")
    print(f"ğŸ” FAISS index saved to: {faiss_path}")
    print(f"ğŸ“„ Valid metadata: {len(valid_metadata)} items")
    print(f"ğŸ”„ Old embeddings have been replaced with new embeddings")
    
    return embeddings, valid_metadata

if __name__ == "__main__":
    print("ğŸ§  EMBEDDINGS BUILDER - OVERWRITE MODE")
    print("=" * 50)
    
    # Kiá»ƒm tra metadata
    metadata_path = Path("index") / "metadata.json"
    if not metadata_path.exists():
        print("âŒ No metadata found!")
        print("ğŸ“ Please run extract_frames_overwrite.py first")
        exit(1)
    
    # Confirm overwrite
    response = input("âš ï¸  This will OVERWRITE existing embeddings. Continue? (y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ Operation cancelled")
        exit(0)
    
    embeddings, metadata = build_embeddings_overwrite()
    
    if embeddings is not False:
        print(f"\nâœ… Ready for testing!")
        print(f"â–¶ï¸  Run: python web_interface.py")
        print(f"ğŸŒ Then visit: http://localhost:8080")
```

### **ğŸš€ Cháº¡y Embedding Builder (Ghi ÄÃ¨)**

```bash
# Build embeddings cho dataset má»›i (ghi Ä‘Ã¨ cÅ©)
python build_embeddings_overwrite.py

# Kiá»ƒm tra káº¿t quáº£
ls -la embeddings/
ls -la index/faiss/
```

---

## ğŸŒ **BÆ°á»›c 6: Cáº­p Nháº­t Web Interface**

### **ğŸ”§ Sá»­a web_interface.py**

```python
# ThÃªm vÃ o web_interface.py
class NewDatasetManager:
    """Manager cho dataset má»›i"""
    
    def __init__(self):
        self.frames_path = Path("frames_new")
        self.index_path = Path("index_new") 
        self.embeddings_path = Path("embeddings_new")
        
    def load_new_dataset(self):
        """Load dataset má»›i"""
        # Load metadata
        metadata_path = self.index_path / "valid_metadata.json"
        with open(metadata_path, 'r', encoding='utf-8') as f:
            self.metadata = json.load(f)
        
        # Load embeddings
        embeddings_file = self.embeddings_path / "clip_vit_base_embeddings.npy"
        self.embeddings = np.load(embeddings_file)
        
        # Load FAISS index
        faiss_file = self.index_path / "faiss" / "clip_vit_base.index"
        self.faiss_index = faiss.read_index(str(faiss_file))
        
        print(f"ğŸ“Š Loaded new dataset: {len(self.metadata)} frames")
        
        return True

# ThÃªm endpoint má»›i
@app.post("/api/switch_dataset")
async def switch_to_new_dataset():
    """Switch to new dataset"""
    global search_engine
    
    try:
        new_manager = NewDatasetManager()
        success = new_manager.load_new_dataset()
        
        if success:
            # Update search engine
            search_engine.frame_records = new_manager.metadata
            search_engine.embeddings = new_manager.embeddings
            search_engine.faiss_index = new_manager.faiss_index
            
            return {
                "status": "success", 
                "message": f"Switched to new dataset with {len(new_manager.metadata)} frames"
            }
    except Exception as e:
        return {"status": "error", "message": str(e)}
```

### **ğŸ–¥ï¸ ThÃªm Button Switch Dataset trong UI**

```html
<!-- ThÃªm vÃ o templates/index.html -->
<div class="dataset-controls">
    <h3>ğŸ“Š Dataset Management</h3>
    <button onclick="switchToNewDataset()" class="btn btn-primary">
        ğŸ”„ Switch to New Dataset (4 videos)
    </button>
    <button onclick="switchToOldDataset()" class="btn btn-secondary">
        ğŸ“š Switch to Original Dataset  
    </button>
</div>

<script>
async function switchToNewDataset() {
    showLoading('Switching to new dataset...');
    
    try {
        const response = await fetch('/api/switch_dataset', {
            method: 'POST'
        });
        
        const result = await response.json();
        
        if (result.status === 'success') {
            showSuccess(result.message);
            // Refresh page Ä‘á»ƒ load dataset má»›i
            setTimeout(() => location.reload(), 1000);
        } else {
            showError(result.message);
        }
    } catch (error) {
        showError('Failed to switch dataset: ' + error.message);
    } finally {
        hideLoading();
    }
}
</script>
```

---

## ğŸš€ **BÆ°á»›c 7: Test Há»‡ Thá»‘ng Má»›i**

### **ğŸ§ª Quick Test Script**

```python
# Táº¡o file: test_new_system.py
import requests
import json

def test_new_dataset_system():
    """Test há»‡ thá»‘ng vá»›i dataset má»›i"""
    
    base_url = "http://localhost:8080"
    
    # Test 1: Health check
    print("ğŸ§ª Test 1: Health check")
    response = requests.get(f"{base_url}/")
    print(f"   Status: {response.status_code}")
    
    # Test 2: Switch to new dataset
    print("\nğŸ§ª Test 2: Switch to new dataset")
    response = requests.post(f"{base_url}/api/switch_dataset")
    result = response.json()
    print(f"   Result: {result}")
    
    # Test 3: Search with new dataset
    print("\nğŸ§ª Test 3: Search test")
    search_queries = [
        "presentation",
        "coding tutorial", 
        "nature scene",
        "interview",
        "person talking"
    ]
    
    for query in search_queries:
        print(f"\n   ğŸ” Testing query: '{query}'")
        response = requests.post(f"{base_url}/api/search", json={
            "query": query,
            "top_k": 3,
            "model": "clip_vit_base"
        })
        
        if response.status_code == 200:
            results = response.json()
            print(f"      âœ… Found {len(results.get('results', []))} results")
            
            for i, result in enumerate(results.get('results', [])[:2]):
                video_name = result.get('video_name', 'Unknown')
                similarity = result.get('similarity', 0)
                timestamp = result.get('timestamp', '00:00')
                print(f"      {i+1}. {video_name} - {timestamp} ({similarity:.1%})")
        else:
            print(f"      âŒ Search failed: {response.status_code}")

if __name__ == "__main__":
    test_new_dataset_system()
```

### **ğŸš€ Cháº¡y Test**

```bash
# Start web interface
python web_interface.py

# Má»Ÿ terminal má»›i vÃ  test
python test_new_system.py

# Test manual qua browser
curl -X POST "http://localhost:8080/api/search" \
     -H "Content-Type: application/json" \
     -d '{"query": "presentation", "top_k": 5}'
```

---

## ğŸ“Š **BÆ°á»›c 8: Complete Reset Workflow**

### **ğŸ”„ All-in-One Reset Script**

```bash
# Táº¡o file: reset_and_rebuild.sh
#!/bin/bash

echo "ğŸš€ Starting complete system reset with new videos..."

# Step 1: Backup old data
echo "ğŸ“¦ Backing up old data..."
mkdir -p backup/$(date +%Y%m%d_%H%M%S)
mv frames backup/$(date +%Y%m%d_%H%M%S)/frames_old 2>/dev/null || true
mv index backup/$(date +%Y%m%d_%H%M%S)/index_old 2>/dev/null || true
mv embeddings backup/$(date +%Y%m%d_%H%M%S)/embeddings_old 2>/dev/null || true

# Step 2: Create new directories
echo "ğŸ“ Creating new directories..."
mkdir -p frames_new index_new embeddings_new

# Step 3: Extract frames
echo "ğŸ¬ Extracting frames from new videos..."
python extract_new_videos.py

# Step 4: Build embeddings
echo "ğŸ§  Building embeddings..."
python build_new_embeddings.py

# Step 5: Update symlinks to point to new data
echo "ğŸ”— Updating symlinks..."
rm -f frames index embeddings
ln -s frames_new frames
ln -s index_new index  
ln -s embeddings_new embeddings

echo "âœ… Complete reset finished!"
echo "ğŸ“Š New dataset ready for use"
echo "ğŸŒ Start web interface: python web_interface.py"
```

### **ğŸ¯ Káº¿t Quáº£ Cuá»‘i CÃ¹ng**

Sau khi hoÃ n thÃ nh táº¥t cáº£ bÆ°á»›c:

```
ğŸ“Š New Dataset Status:
â”œâ”€â”€ ğŸ¬ 4 videos processed
â”œâ”€â”€ ğŸ“ ~4,000 frames extracted (Æ°á»›c tÃ­nh 1 frame/second)
â”œâ”€â”€ ğŸ§  Embeddings built with CLIP ViT Base
â”œâ”€â”€ ğŸ” FAISS index ready for search
â”œâ”€â”€ ğŸŒ Web interface updated
â””â”€â”€ âœ… System ready for use!

ğŸ” Search Performance:
- Query processing: ~0.1-0.3 seconds
- 4 models available: CLIP Base/Large, Chinese CLIP, Sentence Transformers  
- GPU accelerated on RTX 3060
- Real-time model switching enabled
```

### **ğŸ¯ Next Steps**

1. **Test thoroughly**: Thá»­ cÃ¡c query khÃ¡c nhau
2. **Model comparison**: So sÃ¡nh 4 models vá»›i dataset má»›i
3. **Performance tuning**: Tá»‘i Æ°u batch size, GPU memory
4. **Add more videos**: Expand dataset theo thá»i gian

Báº¡n giá» cÃ³ complete workflow Ä‘á»ƒ báº¯t Ä‘áº§u láº¡i tá»« con sá»‘ 0 vá»›i 4 video má»›i!
