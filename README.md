# üé¨ AI Video Search System

H·ªá th·ªëng t√¨m ki·∫øm video th√¥ng minh s·ª≠ d·ª•ng AI ƒë·ªÉ t√¨m nh·ªØng kho·∫£nh kh·∫Øc c·ª• th·ªÉ trong video d·ª±a tr√™n m√¥ t·∫£ vƒÉn b·∫£n. S·ª≠ d·ª•ng m√¥ h√¨nh CLIP ƒë·ªÉ hi·ªÉu c·∫£ n·ªôi dung h√¨nh ·∫£nh v√† vƒÉn b·∫£n.

> ‚úÖ **Portable**: T·∫•t c·∫£ batch files s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi - ho·∫°t ƒë·ªông tr√™n m·ªçi m√°y t√≠nh!

## ‚ö° Kh·ªüi ƒê·ªông Nhanh

### 1. Server T·ªëi ∆Øu Memory (Khuy·∫øn Ngh·ªã) 
```bash
# Ch·∫°y server ·ªïn ƒë·ªãnh, √≠t t·ªën memory
start_server_simple.bat

# Truy c·∫≠p: http://localhost:8001/docs
```

### 2. Server ƒê·∫ßy ƒê·ªß T√≠nh NƒÉng
```bash  
# Ch·∫°y server v·ªõi t·∫•t c·∫£ t√≠nh nƒÉng (c·∫ßn nhi·ªÅu RAM)
start_server_advanced.bat

# Truy c·∫≠p: http://localhost:8000/docs
```

### 3. Setup T·ª´ ƒê·∫ßu (N·∫øu Ch∆∞a C√≥ D·ªØ Li·ªáu)
```bash
# X·ª≠ l√Ω video, t·∫°o index, kh·ªüi ƒë·ªông server
setup_and_run.bat
```

## üéØ So S√°nh 2 Phi√™n B·∫£n

| T√≠nh NƒÉng | Simple (Port 8001) | Advanced (Port 8000) |
|-----------|-------------------|---------------------|
| **Memory** | ‚ö° Th·∫•p (~1GB) | üî• Cao (~4GB+) |
| **Kh·ªüi ƒë·ªông** | üöÄ Nhanh (15s) | üêå Ch·∫≠m (60s) |
| **·ªîn ƒë·ªãnh** | ‚úÖ R·∫•t ·ªïn ƒë·ªãnh | ‚ö†Ô∏è C√≥ th·ªÉ l·ªói memory |
| **T√¨m frame** | ‚úÖ 5 frame t·ªët nh·∫•t | ‚úÖ 5 frame t·ªët nh·∫•t |
| **T√¨m video** | ‚ö° T√¨m c∆° b·∫£n | üî• T√¨m n√¢ng cao + TF-IDF |
| **Top frames/video** | ‚ùå Kh√¥ng | ‚úÖ Top 5 frames m·ªói video |
| **Ph√π h·ª£p** | S·ª≠ d·ª•ng h√†ng ng√†y | Development/Testing |

## üìã Y√™u C·∫ßu H·ªá Th·ªëng

- **Python 3.8+** 
- **FFmpeg** (x·ª≠ l√Ω video)
- **4GB+ RAM** (Simple) / **8GB+ RAM** (Advanced)

### C√†i ƒê·∫∑t FFmpeg:
```bash
# Windows (v·ªõi Chocolatey)
choco install ffmpeg

# Ho·∫∑c t·∫£i t·ª´: https://ffmpeg.org/download.html
```

## ÔøΩ H∆∞·ªõng D·∫´n C√†i ƒê·∫∑t T·ª´ng B∆∞·ªõc

### üìã Y√™u C·∫ßu H·ªá Th·ªëng
- ‚úÖ **Python 3.8+** ƒë√£ c√†i ƒë·∫∑t
- ‚úÖ **FFmpeg** ƒë√£ c√†i ƒë·∫∑t (x·ª≠ l√Ω video)
- ‚úÖ **4GB+ RAM** (8GB+ khuy·∫øn ngh·ªã cho Advanced server)
- ‚úÖ **K·∫øt n·ªëi Internet** (t·∫£i AI model l·∫ßn ƒë·∫ßu)

### üîß C√†i ƒê·∫∑t Nhanh (5 Ph√∫t)

#### B∆∞·ªõc 1: T·∫£i Project
```bash
# Clone t·ª´ GitLab
git clone https://gitlab.com/404-not-found-2/ai-challenge-404-not-found-2.git
cd ai-challenge-404-not-found-2

# Ho·∫∑c t·∫£i ZIP v√† gi·∫£i n√©n
```

#### B∆∞·ªõc 2: T·∫°o Virtual Environment
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac  
python3 -m venv .venv
source .venv/bin/activate
```

#### B∆∞·ªõc 4: Chu·∫©n B·ªã Video Files
```bash
# T·∫°o th∆∞ m·ª•c videos (n·∫øu ch∆∞a c√≥)
mkdir videos

# ƒê·∫∑t file video v√†o th∆∞ m·ª•c videos/
# H·ªó tr·ª£: .mp4, .avi, .mov, .mkv
```

#### B∆∞·ªõc 5: Kh·ªüi ƒê·ªông L·∫ßn ƒê·∫ßu (Ch·ªçn 1 Trong 2)

**Option A: T·ª± ƒê·ªông (Khuy·∫øn Ngh·ªã)**
```bash
# X·ª≠ l√Ω video, t·∫°o index, kh·ªüi ƒë·ªông server m·ªôt l·∫ßn
setup_and_run.bat
```

**Option B: Th·ªß C√¥ng (N·∫øu Mu·ªën Hi·ªÉu T·ª´ng B∆∞·ªõc)**
```bash
# 1. X·ª≠ l√Ω video th√†nh frames
python extract_frames.py

# 2. T·∫°o metadata index  
python build_meta.py

# 3. T·∫°o AI embeddings
python build_embeddings.py

# 4. Kh·ªüi ƒë·ªông server
start_server_simple.bat
```

#### B∆∞·ªõc 6: S·ª≠ D·ª•ng H√†ng Ng√†y
```bash
# Ch·ªâ c·∫ßn ch·∫°y server (d·ªØ li·ªáu ƒë√£ c√≥)
start_server_simple.bat

# Truy c·∫≠p: http://localhost:8001/docs
```

### ‚ö° Quick Start (Cho Ng∆∞·ªùi ƒê√£ Bi·∫øt)
```bash
git clone https://gitlab.com/404-not-found-2/ai-challenge-404-not-found-2.git
cd ai-challenge-404-not-found-2
python -m venv .venv && .venv\Scripts\activate  
pip install -r requirements.txt
# ƒê·∫∑t videos v√†o videos/
setup_and_run.bat
```

## üåê API Endpoints

### Server Simple (Port 8001)
- `GET /docs` - üìö API Documentation  
- `GET /health` - ‚úÖ Tr·∫°ng th√°i server
- `GET /search_frames?q=query` - üîç T√¨m frame ri√™ng l·∫ª
- `GET /search_simple?q=query` - üéØ T√¨m video c∆° b·∫£n

### Server Advanced (Port 8000)  
- `GET /docs` - üìö API Documentation
- `GET /health` - ‚úÖ Tr·∫°ng th√°i server
- `GET /search?q=query` - üî• T√¨m video n√¢ng cao + aggregation
- `GET /search_frames?q=query` - üîç T√¨m frame ri√™ng l·∫ª

## üí° V√≠ D·ª• S·ª≠ D·ª•ng

### T√¨m Frame
```bash
# T√¨m 5 frame g·∫ßn nh·∫•t v·ªõi query
curl "http://localhost:8001/search_frames?q=person walking&top_frames=5"
```

### T√¨m Video (Advanced)
```bash
# T√¨m video v·ªõi top 5 frames t·ªët nh·∫•t m·ªói video
curl "http://localhost:8000/search?q=car driving&clip_weight=0.8"
```

## üÜò X·ª≠ L√Ω L·ªói

| L·ªói | Nguy√™n Nh√¢n | Gi·∫£i Ph√°p |
|-----|-------------|-----------|
| **Memory Error** | Kh√¥ng ƒë·ªß RAM cho Advanced server | D√πng `start_server_simple.bat` |
| **Port Conflict** | Port ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng | Thay ƒë·ªïi port trong file .bat |
| **No Videos Found** | Kh√¥ng c√≥ video trong th∆∞ m·ª•c | ƒê·∫∑t file .mp4 v√†o `videos/` |
| **Missing Index** | Ch∆∞a x·ª≠ l√Ω video | Ch·∫°y `setup_and_run.bat` |
| **FFmpeg Error** | Ch∆∞a c√†i FFmpeg | C√†i FFmpeg t·ª´ ffmpeg.org |
- `GET /search?q=query` - Advanced video search with aggregation
- `GET /search_frames?q=query` - Individual frame search
- `GET /docs` - API documentation

## üõ†Ô∏è Manual Setup (If Needed)

### Step 1: Extract Video Frames
```bash
# Windows PowerShell
$ErrorActionPreference = "Stop"
Get-ChildItem videos -File | ForEach-Object {
  $name = $_.BaseName
  New-Item -ItemType Directory -Force -Path "frames/$name" | Out-Null
  ffmpeg -y -i $_.FullName -vf fps=1 "frames/$name/frame_%06d.jpg"
}

# Linux/Mac Bash
for video in videos/*; do
  name=$(basename "$video" | sed 's/\.[^.]*$//')
```
## üìÅ C·∫•u Tr√∫c Project

```
üì¶ AI Video Search
‚îú‚îÄ‚îÄ üöÄ start_server_simple.bat     # Server t·ªëi ∆∞u memory  
‚îú‚îÄ‚îÄ üî• start_server_advanced.bat   # Server ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng
‚îú‚îÄ‚îÄ üéõÔ∏è start_server.bat            # Menu l·ª±a ch·ªçn
‚îú‚îÄ‚îÄ üõ†Ô∏è setup_and_run.bat           # Setup t·ª´ ƒë·∫ßu
‚îú‚îÄ‚îÄ üìÇ api/
‚îÇ   ‚îú‚îÄ‚îÄ app_simple.py              # Code server t·ªëi ∆∞u
‚îÇ   ‚îî‚îÄ‚îÄ app.py                     # Code server advanced
‚îú‚îÄ‚îÄ üìÇ videos/                     # ƒê·∫∑t file video v√†o ƒë√¢y
‚îú‚îÄ‚îÄ üìÇ frames/                     # Frame ƒë∆∞·ª£c extract
‚îú‚îÄ‚îÄ üìÇ index/                      # Metadata v√† indexes
‚îÇ   ‚îú‚îÄ‚îÄ meta.parquet              # Th√¥ng tin frames
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/               # AI vectors
‚îÇ   ‚îî‚îÄ‚îÄ faiss/                    # Search index
‚îî‚îÄ‚îÄ üìö README.md                  # File n√†y
```

## ‚úÖ Ki·ªÉm Tra Ho·∫°t ƒê·ªông

Sau khi kh·ªüi ƒë·ªông server, b·∫°n s·∫Ω th·∫•y:
```
‚úÖ API server ready!
üîß Memory optimized version loaded  
üìä Ready to search 14402 frames
```

Test c√°c endpoints:
- **Health Check**: http://localhost:8001/health
- **API Docs**: http://localhost:8001/docs  
- **T√¨m Frame**: http://localhost:8001/search_frames?q=person walking

## ÔøΩ Li√™n K·∫øt

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **CLIP Model**: https://github.com/openai/CLIP
- **FAISS**: https://github.com/facebookresearch/faiss

## üìû H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y:
1. Ki·ªÉm tra file `QUICK_START.md` 
2. D√πng server Simple thay v√¨ Advanced
3. ƒê·∫£m b·∫£o ƒë√£ c√†i FFmpeg
4. Ki·ªÉm tra log l·ªói trong terminal

## üÜò X·ª≠ L√Ω L·ªói Th∆∞·ªùng G·∫∑p

### ‚ùå Memory Error (L·ªói B·ªô Nh·ªõ)
```
OSError: [WinError 8] Not enough memory resources
```
**Gi·∫£i ph√°p**: D√πng Simple Server
```bash
start_server_simple.bat  # Thay v√¨ start_server_advanced.bat
```

### ‚ùå Port Already in Use (Port ƒê√£ ƒê∆∞·ª£c S·ª≠ D·ª•ng)
```
OSError: [Errno 48] Address already in use
```
**Gi·∫£i ph√°p**: 
1. ƒê√≥ng server c≈© (Ctrl+C)
2. Ho·∫∑c ƒë·ªïi port trong file .bat

### ‚ùå FFmpeg Not Found
```
'ffmpeg' is not recognized as an internal or external command
```
**Gi·∫£i ph√°p**:
```bash
# Windows (Chocolatey)
choco install ffmpeg

# Ho·∫∑c t·∫£i t·ª´ https://ffmpeg.org/download.html
# Th√™m v√†o PATH environment variable
```

### ‚ùå Python Not Found
```
'python' is not recognized as an internal or external command
```
**Gi·∫£i ph√°p**: C√†i Python 3.8+ t·ª´ https://python.org

### ‚ùå No Videos Found
```
WARNING: No video files found in videos/
```
**Gi·∫£i ph√°p**: ƒê·∫∑t file .mp4/.avi/.mov v√†o th∆∞ m·ª•c `videos/`

### ‚ùå Missing Dependencies
```
ModuleNotFoundError: No module named 'torch'
```
**Gi·∫£i ph√°p**:
```bash
.venv\Scripts\activate
pip install -r requirements.txt
```

## üîó Li√™n K·∫øt H·ªØu √çch

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **CLIP Model**: https://github.com/openai/CLIP
- **FAISS**: https://github.com/facebookresearch/faiss
- **GitLab Repository**: https://gitlab.com/404-not-found-2/ai-challenge-404-not-found-2

## üìû H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. üìñ ƒê·ªçc ph·∫ßn "X·ª≠ L√Ω L·ªói" ·ªü tr√™n
2. ‚ö° D√πng Simple Server thay v√¨ Advanced
3. üîç Ki·ªÉm tra log l·ªói trong terminal
4. üí¨ T·∫°o issue tr√™n GitLab

---
**Made with ‚ù§Ô∏è using AI and CLIP** ü§ñ
   - Saved as `index/faiss/ip_flat.index`

5. **Search API**:
   - `api/app.py` provides FastAPI endpoints
   - Converts text queries to vectors using CLIP
   - Finds similar frames using FAISS
   - Returns ranked video results with timestamps

## üîß API Reference

### Video Search Endpoint (Grouped by Video)

```http
GET /search?q={query}&clip_weight={float}&query_weight={float}&topk_mean={int}&topk_frames={int}
```

### Frame Search Endpoint (Individual Frames) üÜï

```http
GET /search_frames?q={query}&top_frames={int}
```

Returns the top N individual frames closest to your query, potentially from different videos or the same video.

| Parameter | Type | Default | Range | Description |
|-----------|------|---------|-------|-------------|
| `q` | string | **required** | - | Text query to search for |
| `top_frames` | int | 5 | 1-100 | Number of top frames to return |

### Video Search Parameters

| Parameter | Type | Default | Range | Description |
|-----------|------|---------|-------|-------------|
| `q` | string | **required** | - | Text query to search for |
| `clip_weight` | float | 1.0 | 0.0+ | Weight for semantic (CLIP) search |
| `query_weight` | float | 0.0 | 0.0+ | Weight for keyword (TF-IDF) search |
| `topk_mean` | int | 200 | 1-2000 | Number of top frames to average per video |
| `topk_frames` | int | 8000 | 100-50000 | Initial frames retrieved from index |

### Parameter Effects

#### `clip_weight` vs `query_weight`
```bash
# Pure semantic search (understands meaning)
clip_weight=1.0, query_weight=0.0

# Balanced search (meaning + keywords)  
clip_weight=0.7, query_weight=0.3

# Pure keyword search (exact text matching)
clip_weight=0.0, query_weight=1.0
```

#### `topk_mean` (Precision Control)
```bash
topk_mean=50   # Conservative: Top 50 frames ‚Üí Basic precision
topk_mean=200  # Balanced: Top 200 frames ‚Üí Good for 7000+ frame videos  
topk_mean=500  # Comprehensive: Top 500 frames ‚Üí Maximum recall
```

#### `topk_frames` (Search Scope)
```bash
topk_frames=2000  # Fast: Limited scope ‚Üí Quick results
topk_frames=8000  # Balanced: Good for 7000+ frame videos ‚Üí Recommended
topk_frames=15000 # Comprehensive: Full coverage ‚Üí Slower but thorough
```

### Video Search Response Format

```json
{
  "query": "React components tutorial",
  "clip_weight": 1.0,
  "query_weight": 0.0,
  "topk_mean": 50,
  "results": [
    {
      "video_id": "React_Tutorial_Video",
      "video_path": "videos/React_Tutorial_Video.mp4",
      "score": 0.87,
      "frames_used": 25,
      "best_frame_path": "frames/React_Tutorial_Video/frame_000156.jpg",
      "best_frame_timestamp": 156.0,
      "top_frames": [
        {
          "frame_path": "frames/React_Tutorial_Video/frame_000156.jpg",
          "timestamp": 156.0,
          "score": 0.89
        },
        {
          "frame_path": "frames/React_Tutorial_Video/frame_000157.jpg",
          "timestamp": 157.0,
          "score": 0.87
        },
        {
          "frame_path": "frames/React_Tutorial_Video/frame_000158.jpg",
          "timestamp": 158.0,
          "score": 0.85
        },
        {
          "frame_path": "frames/React_Tutorial_Video/frame_000159.jpg",
          "timestamp": 159.0,
          "score": 0.83
        },
        {
          "frame_path": "frames/React_Tutorial_Video/frame_000160.jpg",
          "timestamp": 160.0,
          "score": 0.81
        }
      ]
    }
  ]
}
```

### Frame Search Response Format üÜï

```json
{
  "query": "React components",
  "total_frames_searched": 5,
  "results": [
    {
      "frame_path": "frames/React_Tutorial/frame_000156.jpg",
      "video_id": "React_Tutorial", 
      "timestamp": 156.0,
      "score": 0.89,
      "video_path": "videos/React_Tutorial"
    },
    {
      "frame_path": "frames/JavaScript_Guide/frame_000245.jpg",
      "video_id": "JavaScript_Guide",
      "timestamp": 245.0, 
      "score": 0.87,
      "video_path": "videos/JavaScript_Guide"
    }
  ]
}
```

### Additional Endpoints

```http
# Get video file
GET /videos/{filename}

# Get frame image  
GET /frames/{video_id}/{frame_filename}

# Get video thumbnail
GET /thumbnail/{video_id}

# API documentation
GET /docs
```

## üí° Usage Examples

### Search for Individual Frames üÜï
```bash
# Find 5 most relevant frames (can be from different videos)
curl "http://localhost:8000/search_frames?q=React components&top_frames=5"

# Find 10 frames about Python programming
curl "http://localhost:8000/search_frames?q=Python tutorial&top_frames=10"

# Quick search for coding content
curl "http://localhost:8000/search_frames?q=coding&top_frames=3"
```

### Search for Programming Content (Grouped by Video)
```bash
curl "http://localhost:8000/search?q=Python programming tutorial"
curl "http://localhost:8000/search?q=React components and hooks"
curl "http://localhost:8000/search?q=machine learning explanation"
```

### Adjust Search Behavior
```bash
# Optimized for 7000+ frame videos (recommended)
curl "http://localhost:8000/search?q=coding tutorial&topk_mean=200&topk_frames=8000"

# High precision search (strict matching)
curl "http://localhost:8000/search?q=coding tutorial&topk_mean=100&topk_frames=5000"

# Comprehensive search (maximum coverage)
curl "http://localhost:8000/search?q=coding tutorial&topk_mean=500&topk_frames=15000"

# Combine semantic + keyword search
curl "http://localhost:8000/search?q=React&clip_weight=0.8&query_weight=0.2"
```

### Frontend Integration
```javascript
// Search videos
const response = await fetch('/search?q=React components');
const data = await response.json();

// Display results with thumbnails
data.results.forEach(result => {
  const thumbnail = `/thumbnail/${result.video_id}`;
  const videoUrl = `/videos/${result.video_id}`;
  const jumpTime = result.best_frame_timestamp;
  
  // Create video player that jumps to specific moment
  const video = document.createElement('video');
  video.src = videoUrl;
  video.currentTime = jumpTime;
});
```

## üóÇÔ∏è Project Structure

```
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ app.py              # FastAPI server
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ encode_siglip.py    # AI embedding generation
‚îÇ   ‚îú‚îÄ‚îÄ build_faiss.py      # Vector index creation
‚îÇ   ‚îî‚îÄ‚îÄ text_embed.py       # Text embedding utilities
‚îú‚îÄ‚îÄ index/
‚îÇ   ‚îú‚îÄ‚îÄ meta.parquet        # Frame metadata
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/         # AI-generated vectors
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ frames.f16.mmap
‚îÇ   ‚îî‚îÄ‚îÄ faiss/              # Search indexes
‚îÇ       ‚îî‚îÄ‚îÄ ip_flat.index
‚îú‚îÄ‚îÄ frames/                 # Extracted video frames
‚îú‚îÄ‚îÄ videos/                 # Source video files
‚îú‚îÄ‚îÄ build_meta.py          # Metadata generation script
‚îî‚îÄ‚îÄ README.md              # This documentation
```

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. FFmpeg not found**
```bash
# Windows: Install via chocolatey or download binary
choco install ffmpeg

# Linux: Install via package manager
sudo apt install ffmpeg
```

**2. CUDA out of memory**
```python
# In scripts/encode_siglip.py, use CPU instead
DEVICE = 'cpu'  # Change from 'cuda'
```

**3. Import errors**
```bash
# Reinstall dependencies
pip install --upgrade torch transformers faiss-cpu
```

**4. Slow search performance**
```bash
# For 7000+ frame videos, use optimized parameters
curl "http://localhost:8000/search?q=tutorial&topk_frames=5000&topk_mean=150"

# For faster results with good accuracy
curl "http://localhost:8000/search?q=tutorial&topk_frames=3000&topk_mean=100"
```

### Performance Tuning

**For Large Video Collections (7000+ frames per video):**
- Use `topk_frames=8000-15000` for comprehensive search
- Set `topk_mean=200-500` for balanced precision/recall
- Use GPU if available (`DEVICE = 'cuda'`)
- Consider using `faiss-gpu` instead of `faiss-cpu`

**For Real-time Applications:**
- Use `topk_frames=3000-5000` for faster response
- Set `topk_mean=100-200` for good accuracy
- Cache frequent queries
- Use smaller batch sizes during indexing

## üî¨ Technical Details

### AI Models Used
- **CLIP**: `openai/clip-vit-base-patch32`
  - 512-dimensional embeddings
  - Understands both text and images
  - Pre-trained on 400M image-text pairs

### Vector Search
- **FAISS IndexFlatIP**: Inner product similarity
- **Normalization**: L2 normalized vectors for cosine similarity
- **Search complexity**: O(N) where N = number of frames

### File Formats
- **Embeddings**: Float16 memory-mapped files (.mmap)
- **Metadata**: Parquet format for fast loading
- **Index**: FAISS binary format

## üßÆ **TO√ÅN H·ªåC V√Ä KI·∫æN TH·ª®C ·∫®N TRONG H·ªÜ TH·ªêNG**

### **1. üéØ CLIP MODEL - CONTRASTIVE LEARNING**

#### **A. Text Embedding Process:**
```python
# Qu√° tr√¨nh chuy·ªÉn ƒë·ªïi text th√†nh vector 512 chi·ªÅu
def embed_text(query: str) -> np.ndarray:
    # 1. Tokenization: "person walking" ‚Üí [49406, 2533, 3788, 49407]
    # 2. Transformer: tokens ‚Üí hidden_states (512 dim)
    # 3. Normalization: vector / ||vector||‚ÇÇ
```

**üî¨ To√°n h·ªçc ·∫©n:**

**Self-Attention Mechanism:**
```
Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V

Trong ƒë√≥:
- Q = Query matrix (512 dim)
- K = Key matrix (512 dim)  
- V = Value matrix (512 dim)
- d_k = 512 (dimension of keys)
- ‚àöd_k = ‚àö512 ‚âà 22.6 (scaling factor)
```

**Layer Normalization:**
```
LN(x) = Œ≥ * (x - Œº)/œÉ + Œ≤

Œº = mean(x)     # Trung b√¨nh c·ªßa vector
œÉ = std(x)      # ƒê·ªô l·ªách chu·∫©n  
Œ≥, Œ≤ = learnable parameters
```

**L2 Normalization (Final Step):**
```
normalized_vector = vector / ||vector||‚ÇÇ

||vector||‚ÇÇ = ‚àö(‚àë·µ¢‚Çå‚ÇÅ‚Åµ¬π¬≤ v·µ¢¬≤)  # Euclidean norm

K·∫øt qu·∫£: ||normalized_vector||‚ÇÇ = 1.0
```

#### **B. Vision Transformer (ViT) cho Images:**

**Patch Embedding:**
```
Image (224√ó224√ó3) ‚Üí Patches (196√ó768)

- M·ªói patch = 16√ó16 pixels
- S·ªë patches = (224/16)¬≤ = 196 patches  
- Embedding dim = 768 ‚Üí project to 512
```

**Positional Encoding:**
```
PE(pos,2i) = sin(pos/10000^(2i/d_model))
PE(pos,2i+1) = cos(pos/10000^(2i/d_model))

pos = position of patch (0-195)
i = dimension index (0-255)  
d_model = 512
```

### **2. üéØ FAISS VECTOR SEARCH**

#### **A. Cosine Similarity via Inner Product:**

```python
# V·ªõi normalized vectors: cosine_similarity = inner_product
similarity = query_vector ¬∑ frame_vector = ‚àë·µ¢‚Çå‚ÇÅ‚Åµ¬π¬≤ q·µ¢ √ó f·µ¢
```

**üî¨ To√°n h·ªçc ·∫©n:**

**Cosine Similarity Formula:**
```
cos_sim(a,b) = (a¬∑b)/(||a|| √ó ||b||)

V√¨ vectors ƒë√£ normalized (||a|| = ||b|| = 1):
cos_sim(a,b) = a¬∑b = inner_product(a,b)

K·∫øt qu·∫£ ‚àà [-1, 1]:
- 1.0 = ho√†n to√†n gi·ªëng nhau
- 0.0 = kh√¥ng li√™n quan  
- -1.0 = ho√†n to√†n ƒë·ªëi l·∫≠p
```

**FAISS IndexFlatIP Search:**
```
Brute Force Algorithm:
for each frame_vector in database:
    score = query_vector ¬∑ frame_vector  
    if score > threshold:
        add (score, frame_index) to results

Sort results by score (descending)
Return top_k results

Time Complexity: O(N √ó D)  
N = s·ªë frames (~14,402)
D = embedding dimension (512)
```

#### **B. Memory-Mapped Storage:**

```python
# Float16 precision cho ti·∫øt ki·ªám memory
mem = np.memmap(path, dtype='float16', shape=(N, 512))
```

**üî¨ To√°n h·ªçc ·∫©n:**

**Float16 vs Float32:**
```
Float16: 1 bit sign + 5 bits exponent + 10 bits mantissa
- Range: ¬±6.55√ó10‚Å¥
- Precision: ~3-4 decimal digits
- Memory: N √ó 512 √ó 2 bytes = N √ó 1KB per frame

Float32: 1 bit sign + 8 bits exponent + 23 bits mantissa  
- Range: ¬±3.4√ó10¬≥‚Å∏
- Precision: ~6-7 decimal digits
- Memory: N √ó 512 √ó 4 bytes = N √ó 2KB per frame

Quantization Error: |float32_value - float16_value| < 0.1%
```

### **3. üéØ SCORE AGGREGATION & RANKING**

#### **A. Video-Level Scoring:**

```python
# Max pooling strategy
video_score = max(frame_scores)
= max{cos_sim(query, frame‚ÇÅ), cos_sim(query, frame‚ÇÇ), ...}
```

**üî¨ Alternative Aggregation Methods:**

**Mean Pooling:**
```
video_score = (1/n) √ó ‚àë·µ¢‚Çå‚ÇÅ‚Åø cos_sim(query, frame·µ¢)
```

**Weighted Average:**
```
video_score = ‚àë·µ¢‚Çå‚ÇÅ‚Åø w·µ¢ √ó cos_sim(query, frame·µ¢)
where ‚àëw·µ¢ = 1
```

**Top-K Mean (Advanced Server):**
```python
# topk_mean = 50 (parameter)
sorted_scores = sorted(frame_scores, reverse=True)
top_k_scores = sorted_scores[:50]
video_score = mean(top_k_scores)
```

#### **B. Statistical Interpretation:**

**Score Ranges:**
```
Score ‚â• 0.9:  Excellent match (>90% similarity)
Score 0.7-0.9: Good match (70-90% similarity)  
Score 0.5-0.7: Moderate match (50-70% similarity)
Score < 0.5:   Poor match (<50% similarity)
```

### **4. üéØ BATCH PROCESSING & OPTIMIZATION**

#### **A. GPU Memory Management:**

```python
# Batch processing ƒë·ªÉ t·ªëi ∆∞u GPU
BATCH_SIZE = 64  # T√πy thu·ªôc GPU memory
```

**üî¨ Memory Calculations:**

**Single Image Processing:**
```
Input: 224√ó224√ó3√ó4 bytes = 600KB (float32)
Intermediate activations: ~50-100MB per image
Peak GPU memory: ~2-4GB for CLIP-ViT-Base
```

**Batch Processing:**
```
Batch of 64 images:
- Input memory: 64 √ó 600KB = 38.4MB  
- Activation memory: 64 √ó 100MB = 6.4GB
- Total GPU memory needed: ~8-10GB
```

#### **B. Numerical Stability:**

**Normalization with Epsilon:**
```python
# Tr√°nh division by zero
normalized = vector / (||vector||‚ÇÇ + Œµ)
where Œµ = 1e-12
```

**Gradient Flow:**
```
‚àÇLoss/‚àÇvector = ‚àÇLoss/‚àÇnormalized √ó ‚àÇnormalized/‚àÇvector

‚àÇnormalized/‚àÇvector = (I - normalized‚äónormalized) / ||vector||
```

### **5. üéØ ADVANCED CONCEPTS**

#### **A. Contrastive Learning (CLIP Training):**

**Contrastive Loss Function:**
```
L = -log(exp(sim(text,image‚Å∫)/œÑ) / ‚àë‚±º exp(sim(text,image‚±º)/œÑ))

œÑ = temperature parameter = 0.07
image‚Å∫ = positive pair (correct image for text)
image‚±º = all images in batch (including negatives)
```

**Symmetrical Training:**
```
Total_Loss = L(text‚Üíimage) + L(image‚Üítext)
```

#### **B. Dimensional Analysis:**

**512-Dimensional Embedding Space:**
```
Information capacity: 2^(512√ó16) possible vectors (float16)
‚âà 10^2466 possible embeddings

Unit sphere S^511:
- Most vectors are nearly orthogonal
- Average cosine similarity ‚âà 0 for random vectors
- Meaningful clusters form in high-density regions
```

### **6. üéØ PERFORMANCE METRICS**

#### **A. Search Performance:**

```
Query Processing: ~50-100ms (CPU) / ~10-20ms (GPU)
FAISS Search: ~5-15ms for 14K frames
Total Response: ~100-200ms per query

Throughput: ~10-50 queries/second (depending on hardware)
```

#### **B. Memory Usage:**

```
Metadata (meta.parquet): ~1-2MB  
Embeddings (14K√ó512√ó2): ~14.8MB
FAISS Index: ~15-20MB
Model weights: ~150MB (CLIP)
Runtime memory: 1-4GB (Simple vs Advanced)
```

### **üìä T√≥m T·∫Øt C√¥ng Th·ª©c Ch√≠nh:**

1. **Text/Image ‚Üí Embedding**: `CLIP(input) ‚Üí normalize(vector‚ÇÖ‚ÇÅ‚ÇÇ)`
2. **Similarity Search**: `score = query ¬∑ frame` (inner product)  
3. **Video Ranking**: `video_score = max(frame_scores)` or `mean(top_k)`
4. **Memory Efficiency**: `float16` storage, memory mapping
5. **Batch Processing**: Parallel GPU computation for speed

**H·ªá th·ªëng k·∫øt h·ª£p Linear Algebra, Deep Learning, Information Retrieval, v√† Computer Vision ƒë·ªÉ t·∫°o ra AI search engine m·∫°nh m·∫Ω!**

## üìù License

This project is licensed under the MIT License - see the LICENSE file for details.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üôè Acknowledgments

- **OpenAI** for the CLIP model
- **Facebook Research** for FAISS vector search
- **FastAPI** for the web framework
- **FFmpeg** for video processing

---

**Built with ‚ù§Ô∏è for intelligent video search**
